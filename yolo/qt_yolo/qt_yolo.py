from PySide6 import QtWidgets, QtCore, QtGui
import cv2, os, time
from threading import Thread
from pathlib import Path

# https://www.byhy.net/
# ä¸ç„¶æ¯æ¬¡YOLOå¤„ç†éƒ½ä¼šè¾“å‡ºè°ƒè¯•ä¿¡æ¯
os.environ['YOLO_VERBOSE'] = 'False'
from ultralytics import YOLO 

class MWindow(QtWidgets.QMainWindow):

    def __init__(self):

        super().__init__()

        # è®¾ç½®ç•Œé¢
        self.setupUI()

        self.camBtn.clicked.connect(self.startCamera)
        self.stopBtn.clicked.connect(self.stop)

        # å®šä¹‰å®šæ—¶å™¨ï¼Œç”¨äºæ§åˆ¶æ˜¾ç¤ºè§†é¢‘çš„å¸§ç‡
        self.timer_camera = QtCore.QTimer()
        # å®šæ—¶åˆ°äº†ï¼Œå›è°ƒ self.show_camera
        self.timer_camera.timeout.connect(self.show_camera)

        # åŠ è½½ YOLO nano æ¨¡å‹ï¼Œç¬¬ä¸€æ¬¡æ¯”è¾ƒè€—æ—¶ï¼Œè¦20ç§’å·¦å³
        model_path = Path('../model').resolve()
        self.model = YOLO(model_path /'yolov8n.pt')

        # è¦å¤„ç†çš„è§†é¢‘å¸§å›¾ç‰‡é˜Ÿåˆ—ï¼Œç›®å‰å°±æ”¾1å¸§å›¾ç‰‡
        self.frameToAnalyze = []

        # å¯åŠ¨å¤„ç†è§†é¢‘å¸§ç‹¬ç«‹çº¿ç¨‹
        Thread(target=self.frameAnalyzeThreadFunc,daemon=True).start()

    def setupUI(self):

        self.resize(1200, 800)

        self.setWindowTitle('YOLO-Qt æ¼”ç¤º')

        # central Widget
        centralWidget = QtWidgets.QWidget(self)
        self.setCentralWidget(centralWidget)

        # central Widget é‡Œé¢çš„ ä¸» layout
        mainLayout = QtWidgets.QVBoxLayout(centralWidget)

        # ç•Œé¢çš„ä¸ŠåŠéƒ¨åˆ† : å›¾å½¢å±•ç¤ºéƒ¨åˆ†
        topLayout = QtWidgets.QHBoxLayout()
        self.label_ori_video = QtWidgets.QLabel(self)
        self.label_treated = QtWidgets.QLabel(self)
        self.label_ori_video.setMinimumSize(520,400)
        self.label_treated.setMinimumSize(520,400)
        self.label_ori_video.setStyleSheet('border:1px solid #D7E2F9;')
        self.label_treated.setStyleSheet('border:1px solid #D7E2F9;')

        topLayout.addWidget(self.label_ori_video)
        topLayout.addWidget(self.label_treated)

        mainLayout.addLayout(topLayout)

        # ç•Œé¢ä¸‹åŠéƒ¨åˆ†ï¼š è¾“å‡ºæ¡† å’Œ æŒ‰é’®
        groupBox = QtWidgets.QGroupBox(self)

        bottomLayout =  QtWidgets.QHBoxLayout(groupBox)
        self.textLog = QtWidgets.QTextBrowser()
        bottomLayout.addWidget(self.textLog)

        mainLayout.addWidget(groupBox)

        btnLayout = QtWidgets.QVBoxLayout()
        self.videoBtn = QtWidgets.QPushButton('ğŸï¸è§†é¢‘æ–‡ä»¶')
        self.camBtn   = QtWidgets.QPushButton('ğŸ“¹æ‘„åƒå¤´')
        self.stopBtn  = QtWidgets.QPushButton('ğŸ›‘åœæ­¢')
        btnLayout.addWidget(self.videoBtn)
        btnLayout.addWidget(self.camBtn)
        btnLayout.addWidget(self.stopBtn)
        bottomLayout.addLayout(btnLayout)


    def startCamera(self):

        # å‚è€ƒ https://docs.opencv.org/3.4/dd/d43/tutorial_py_video_display.html

        # åœ¨ windowsä¸ŠæŒ‡å®šä½¿ç”¨ cv2.CAP_DSHOW ä¼šè®©æ‰“å¼€æ‘„åƒå¤´å¿«å¾ˆå¤šï¼Œ 
        # åœ¨ Linux/Macä¸Š æŒ‡å®š V4L, FFMPEG æˆ–è€… GSTREAMER
        self.cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)
        if not self.cap.isOpened():
            print("1å·æ‘„åƒå¤´ä¸èƒ½æ‰“å¼€")
            return()

        if self.timer_camera.isActive() == False:  # è‹¥å®šæ—¶å™¨æœªå¯åŠ¨
            self.timer_camera.start(50)


    def show_camera(self):

        ret, frame = self.cap.read()  # ä»è§†é¢‘æµä¸­è¯»å–
        if not ret:
            return

        # æŠŠè¯»åˆ°çš„16:10å¸§çš„å¤§å°é‡æ–°è®¾ç½® 
        frame = cv2.resize(frame, (520, 400))          
        # è§†é¢‘è‰²å½©è½¬æ¢å›RGBï¼ŒOpenCV images as BGR
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  
        qImage = QtGui.QImage(frame.data, frame.shape[1], frame.shape[0],
                                 QtGui.QImage.Format_RGB888)  # å˜æˆQImageå½¢å¼
        # å¾€æ˜¾ç¤ºè§†é¢‘çš„Labelé‡Œ æ˜¾ç¤ºQImage
        self.label_ori_video.setPixmap(QtGui.QPixmap.fromImage(qImage)) 

        # å¦‚æœå½“å‰æ²¡æœ‰å¤„ç†ä»»åŠ¡
        if not self.frameToAnalyze:
            self.frameToAnalyze.append(frame)

    def frameAnalyzeThreadFunc(self):

        while True:
            if not self.frameToAnalyze:
                time.sleep(0.01)
                continue

            frame = self.frameToAnalyze.pop(0)

            results = self.model(frame)[0]

            img = results.plot(line_width=1)    

            qImage = QtGui.QImage(img.data, img.shape[1], img.shape[0],
                                    QtGui.QImage.Format_RGB888)  # å˜æˆQImageå½¢å¼

            self.label_treated.setPixmap(QtGui.QPixmap.fromImage(qImage))  # å¾€æ˜¾ç¤ºLabelé‡Œ æ˜¾ç¤ºQImage

            time.sleep(0.5)

    def stop(self):
        self.timer_camera.stop()  # å…³é—­å®šæ—¶å™¨
        self.cap.release()  # é‡Šæ”¾è§†é¢‘æµ
        self.label_ori_video.clear()  # æ¸…ç©ºè§†é¢‘æ˜¾ç¤ºåŒºåŸŸ        
        self.label_treated.clear()  # æ¸…ç©ºè§†é¢‘æ˜¾ç¤ºåŒºåŸŸ


app = QtWidgets.QApplication()
window = MWindow()
window.show()
app.exec()